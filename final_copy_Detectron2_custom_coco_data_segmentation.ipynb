{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_copy Detectron2_custom_coco_data_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ericshermancs/detectron2/blob/master/final_copy_Detectron2_custom_coco_data_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYYSpoaJ31CI"
      },
      "source": [
        "CSCI 381 Final Project by: Brandon Draves, Eric Sherman, Desiree Urban"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7ed3e4-ea04-42d7-9eaf-a390b29b521b"
      },
      "source": [
        "#!pip install -U torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/fvcore.git\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/fvcore.git\n",
            "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-n5najxvm\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-n5najxvm\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (1.18.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (4.41.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (7.0.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1.2) (0.8.7)\n",
            "Collecting iopath>=0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/9a/87a281c8cfc0ad1fceb228a4f854d02f19b2c2395476dd573327709b52ae/iopath-0.1.2.tar.gz\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: fvcore, pyyaml, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.2-cp36-none-any.whl size=44589 sha256=68823ab951672e10099325de57a054f063285b3a6d112ac6c210d6db5d000935\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-at41l477/wheels/48/53/79/3c6485543a4455a0006f5db590ab9957622b6227011941de06\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44620 sha256=cf88771c3fec17a55240d132d0d97ae3ee07c6cb5cc1a97ee3a572e081fb07d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.2-cp36-none-any.whl size=10505 sha256=5cd5a81e182dc9ebe96578f6881157ce43099646a01298601d7d2731fa7f2933\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/01/e4/1b68f5a2a6b9450ea4246d91840a77e1169f7d4722d76bbc47\n",
            "Successfully built fvcore pyyaml iopath\n",
            "Installing collected packages: pyyaml, yacs, portalocker, iopath, fvcore\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed fvcore-0.1.2 iopath-0.1.2 portalocker-2.0.0 pyyaml-5.3.1 yacs-0.1.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6fffe1c-4c4b-4b83-c162-e47cf777a15b"
      },
      "source": [
        "# import our own detectron2 repo\n",
        "\n",
        "!git clone https://github.com/ericshermancs/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'detectron2_repo'...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 9569 (delta 0), reused 0 (delta 0), pack-reused 9564\u001b[K\n",
            "Receiving objects: 100% (9569/9569), 15.71 MiB | 33.94 MiB/s, done.\n",
            "Resolving deltas: 100% (7014/7014), done.\n",
            "Obtaining file:///content/detectron2_repo\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (1.1.0)\n",
            "Collecting Pillow>=7.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.8.7)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (3.2.2)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (4.41.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (2.3.0)\n",
            "Requirement already satisfied: fvcore>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.1.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (2.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.6/dist-packages (from detectron2==0.3) (1.3.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.3) (5.3.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.3) (2.4.7)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.34.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.17.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (0.36.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (50.3.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (0.10.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.3) (1.15.0)\n",
            "Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from fvcore>=0.1.2->detectron2==0.3) (0.1.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.2->detectron2==0.3) (0.29.21)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.3) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.3) (3.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (1.24.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from iopath>=0.1.2->fvcore>=0.1.2->detectron2==0.3) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.3) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->detectron2==0.3) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.3) (3.4.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow, detectron2\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "  Running setup.py develop for detectron2\n",
            "Successfully installed Pillow-8.0.1 detectron2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa4610f-8d0c-49fb-8c63-0b7265a42c3a"
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import importlib\n",
        "import detectron2\n",
        "# importlib.reload(detectron2)\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2bjrfb2LDeo"
      },
      "source": [
        "# Train on a custom COCO dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A99aL0eaou77",
        "outputId": "9b0bbf23-8f2a-432b-a88e-2d730ba8a3a0"
      },
      "source": [
        "# uncomment below if access model and metadata from google drive\r\n",
        "# from google.colab import drive\r\n",
        "# drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qg7zSVOulkb"
      },
      "source": [
        "# download, decompress the data\n",
        "#!wget https://github.com/Tony607/detectron2_instance_segmentation_demo/releases/download/V0.1/data.zip\n",
        "#!unzip data.zip > /dev/null\n",
        "\n",
        "!wget --directory-prefix=downloads http://calvin.inf.ed.ac.uk/wp-content/uploads/data/cocostuffdataset/cocostuff-10k-v1.1.zip\n",
        "# uncomment below if in your google drive\n",
        "# !unzip /content/drive/MyDrive/cocostuff-10k-v1.1.zip -d cocostuff-10k-v1.1/ \n",
        "!mkdir downloads\n",
        "!wget --directory-prefix=downloads http://calvin.inf.ed.ac.uk/wp-content/uploads/data/cocostuffdataset/cocostuff-10k-v1.1.json\n",
        "# uncomment below if in google drive\n",
        "# !cp /content/drive/MyDrive/cocostuff-10k-v1.1.json downloads/cocostuff-10k-v1.1.json\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PchRsZxADFAY"
      },
      "source": [
        "import json\r\n",
        "ann_file = json.load(open('downloads/cocostuff-10k-v1.1.json'))\r\n",
        "id_list = [x[\"id\"] for x in ann_file['annotations']]\r\n",
        "\r\n",
        "from collections import Counter\r\n",
        "import pycocotools\r\n",
        "counter = Counter(id_list)\r\n",
        "duplicates_set = {i[0] for i in counter.most_common() if i[1]>1}\r\n",
        "max_id = max(id_list)\r\n",
        "\r\n",
        "dupe_counter = 1\r\n",
        "rle_ann_list = []\r\n",
        "for annotation in ann_file['annotations']:\r\n",
        "    _id = annotation['id']\r\n",
        "    if 'iscrowd' in annotation:\r\n",
        "        if annotation['iscrowd'] == 1:\r\n",
        "            rle_ann_list.append(annotation)\r\n",
        "        annotation['iscrowd'] = 0\r\n",
        "        \r\n",
        "        \r\n",
        "    if _id in duplicates_set:\r\n",
        "        annotation['id'] = max_id + dupe_counter\r\n",
        "        dupe_counter += 1\r\n",
        "\r\n",
        "    if isinstance(annotation['segmentation'], list):\r\n",
        "        if isinstance(annotation['segmentation'][0], dict):\r\n",
        "\r\n",
        "            decoding = pycocotools.mask.decode(annotation['segmentation'][0])\r\n",
        "\r\n",
        "            _contours, hierarchy = cv2.findContours(decoding, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\r\n",
        "            \r\n",
        "            contours = map(np.squeeze, _contours)  # removing redundant dimensions\r\n",
        "            coords = []\r\n",
        "            for cont in contours:\r\n",
        "                coords.append(cont.flatten().tolist())\r\n",
        "\r\n",
        "            annotation['segmentation'] = coords\r\n",
        "    \r\n",
        "    if isinstance(annotation['bbox'][0], list):\r\n",
        "      annotation['bbox'] = annotation['bbox'][0]\r\n",
        "    \r\n",
        "    \r\n",
        "with open('downloads/cocostuff_unique.json', 'w+') as outfile:\r\n",
        "    json.dump(ann_file, outfile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnkg1PByUjGQ"
      },
      "source": [
        "#from detectron2.data.datasets import register_coco_instances\n",
        "#register_coco_instances(\"fruits_nuts\", {}, \"./data/trainval.json\", \"./data/images\")\n",
        "import time\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "CURRENT_CATALOG_NAME = str(time.time())\n",
        "register_coco_instances( CURRENT_CATALOG_NAME, {}, 'downloads/cocostuff_unique.json' ,'./cocostuff-10k-v1.1/images' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWknKqWTWIw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ada030e-919c-4b77-eaf9-fc2cbe5c52ca"
      },
      "source": [
        "\n",
        "fruits_nuts_metadata = MetadataCatalog.get( CURRENT_CATALOG_NAME )\n",
        "#coco10k_metadata = MetadataCatalog.get( 'COCO10k' )\n",
        "dataset_dict = DatasetCatalog.get( CURRENT_CATALOG_NAME )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/13 04:07:20 d2.data.datasets.coco]: \u001b[0mLoading downloads/cocostuff_unique.json takes 6.59 seconds.\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/13 04:07:20 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[12/13 04:07:20 d2.data.datasets.coco]: \u001b[0mLoaded 10000 images in COCO format from downloads/cocostuff_unique.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/13 04:07:21 d2.data.datasets.coco]: \u001b[0mFiltered out 12 instances without valid segmentation. There might be issues in your dataset generation process. A valid polygon should be a list[float] with even length >= 6.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7unkuuiqLdqd"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "import os\n",
        "\n",
        "cfg = get_cfg()\n",
        "#cfg.merge_from_file(\"./detectron2_repo/configs/COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\")\n",
        "cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "cfg.DATASETS.TRAIN = (CURRENT_CATALOG_NAME,)\n",
        "cfg.DATASETS.TEST = ()   # no metrics implemented for this dataset\n",
        "cfg.DATALOADER.NUM_WORKERS = 8\n",
        "#cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_C4_1x/137257644/model_final_721ade.pkl\"  # initialize from model zoo\n",
        "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
        "\n",
        "cfg.SOLVER.IMS_PER_BATCH = 11\n",
        "cfg.SOLVER.BASE_LR = 0.02\n",
        "cfg.SOLVER.MAX_ITER = 1500    # 300 iterations seems good enough, but you can certainly train longer\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this toy dataset\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 183  # 3 classes (data, fig, hazelnut)\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "print( 'before trainer' )\n",
        "trainer = DefaultTrainer(cfg)\n",
        "print('after trainer')\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e4vdDIOXyxF"
      },
      "source": [
        "Now, we perform inference with the trained model on the fruits_nuts dataset. First, let's create a predictor using the model we just trained:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5nEuMELeq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c45eef3-619e-48b8-97d8-18a8f13d0045"
      },
      "source": [
        "import os\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "print(os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg.DATASETS.TEST = (CURRENT_CATALOG_NAME, )\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./output/model_final.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWq1XHfDWiXO"
      },
      "source": [
        "Then, we randomly select several samples to visualize the prediction results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5LhISJqWXgM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "610bfd3c-fc4d-4326-e406-8a5df7e4c772"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "!wget https://render.fineartamerica.com/images/rendered/default/poster/10/8/break/images-medium-5/lazy-sunday-scenic-view-of-mammoth-lakes-in-california-with-people-relaxing-and-fishing-jamie-pham.jpg -O test.png\n",
        "im = cv2.imread(\"test.png\")\n",
        "print(type(predictor))\n",
        "outputs = predictor(im)\n",
        "v = Visualizer(im[:, :, ::-1],\n",
        "                metadata=fruits_nuts_metadata, \n",
        "                scale=0.8, \n",
        "                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        ")\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0c26b78f6a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColorMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://render.fineartamerica.com/images/rendered/default/poster/10/8/break/images-medium-5/lazy-sunday-scenic-view-of-mammoth-lakes-in-california-with-people-relaxing-and-fishing-jamie-pham.jpg -O test.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thRYgRLgrBcV"
      },
      "source": [
        "from detectron2.engine.custom import CustomPredictor\r\n",
        "MODEL_PATH = '/content/drive/MyDrive/torch_model.pth'\r\n",
        "# metadata = '/content/drive/MyDrive/metadata.txt'\r\n",
        "p = CustomPredictor(trainer.model)\r\n",
        "p.load_metadata(fruits_nuts_metadata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3HLXWzt0fm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "732ea982-2b7a-4883-b5f2-0584a2d800fc"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\r\n",
        "from detectron2.data import build_detection_test_loader\r\n",
        "evaluator = COCOEvaluator(CURRENT_CATALOG_NAME, (\"bbox\", \"segm\"), False, output_dir=\"./output/\")\r\n",
        "val_loader = build_detection_test_loader(cfg, CURRENT_CATALOG_NAME )\r\n",
        "\r\n",
        "print(inference_on_dataset(p.model, val_loader, evaluator))\r\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/13 04:07:50 d2.data.datasets.coco]: \u001b[0mLoading downloads/cocostuff_unique.json takes 8.69 seconds.\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/13 04:07:50 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[12/13 04:07:50 d2.data.datasets.coco]: \u001b[0mLoaded 10000 images in COCO format from downloads/cocostuff_unique.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/13 04:07:50 d2.data.datasets.coco]: \u001b[0mFiltered out 12 instances without valid segmentation. There might be issues in your dataset generation process. A valid polygon should be a list[float] with even length >= 6.\n",
            "\u001b[32m[12/13 04:07:51 d2.data.build]: \u001b[0mDistribution of instances among all 171 categories:\n",
            "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 22601        |    bicycle    | 552          |      car      | 3562         |\n",
            "|  motorcycle   | 703          |   airplane    | 508          |      bus      | 524          |\n",
            "|     train     | 350          |     truck     | 850          |     boat      | 986          |\n",
            "| traffic light | 1190         | fire hydrant  | 171          |   stop sign   | 157          |\n",
            "| parking meter | 90           |     bench     | 784          |     bird      | 802          |\n",
            "|      cat      | 428          |      dog      | 441          |     horse     | 541          |\n",
            "|     sheep     | 785          |      cow      | 654          |   elephant    | 530          |\n",
            "|     bear      | 100          |     zebra     | 452          |    giraffe    | 451          |\n",
            "|   backpack    | 777          |   umbrella    | 902          |    handbag    | 1037         |\n",
            "|      tie      | 623          |   suitcase    | 563          |    frisbee    | 222          |\n",
            "|     skis      | 549          |   snowboard   | 236          |  sports ball  | 521          |\n",
            "|     kite      | 795          | baseball bat  | 279          | baseball gl.. | 358          |\n",
            "|  skateboard   | 498          |   surfboard   | 466          | tennis racket | 397          |\n",
            "|    bottle     | 1889         |  wine glass   | 627          |      cup      | 1715         |\n",
            "|     fork      | 430          |     knife     | 652          |     spoon     | 495          |\n",
            "|     bowl      | 1218         |    banana     | 930          |     apple     | 464          |\n",
            "|   sandwich    | 374          |    orange     | 539          |   broccoli    | 464          |\n",
            "|    carrot     | 590          |    hot dog    | 234          |     pizza     | 503          |\n",
            "|     donut     | 734          |     cake      | 555          |     chair     | 3250         |\n",
            "|     couch     | 479          | potted plant  | 801          |      bed      | 367          |\n",
            "| dining table  | 1412         |    toilet     | 379          |      tv       | 550          |\n",
            "|    laptop     | 436          |     mouse     | 228          |    remote     | 459          |\n",
            "|   keyboard    | 300          |  cell phone   | 556          |   microwave   | 135          |\n",
            "|     oven      | 256          |    toaster    | 22           |     sink      | 465          |\n",
            "| refrigerator  | 214          |     book      | 2143         |     clock     | 541          |\n",
            "|     vase      | 583          |   scissors    | 110          |  teddy bear   | 392          |\n",
            "|  hair drier   | 9            |  toothbrush   | 140          |    banner     | 274          |\n",
            "|    blanket    | 50           |    branch     | 54           |    bridge     | 101          |\n",
            "| building-ot.. | 1610         |     bush      | 674          |    cabinet    | 338          |\n",
            "|     cage      | 33           |   cardboard   | 82           |    carpet     | 306          |\n",
            "| ceiling-other | 651          | ceiling-tile  | 48           |     cloth     | 162          |\n",
            "|    clothes    | 108          |    clouds     | 1524         |    counter    | 371          |\n",
            "|   cupboard    | 272          |    curtain    | 382          |  desk-stuff   | 189          |\n",
            "|     dirt      | 579          |  door-stuff   | 539          |     fence     | 939          |\n",
            "| floor-marble  | 50           |  floor-other  | 502          |  floor-stone  | 70           |\n",
            "|  floor-tile   | 389          |  floor-wood   | 440          |    flower     | 180          |\n",
            "|      fog      | 35           |  food-other   | 208          |     fruit     | 73           |\n",
            "| furniture-o.. | 639          |     grass     | 1762         |    gravel     | 211          |\n",
            "| ground-other  | 746          |     hill      | 270          |     house     | 415          |\n",
            "|    leaves     | 114          |     light     | 632          |      mat      | 67           |\n",
            "|     metal     | 273          | mirror-stuff  | 269          |     moss      | 13           |\n",
            "|   mountain    | 211          |      mud      | 58           |    napkin     | 65           |\n",
            "|      net      | 148          |     paper     | 234          |   pavement    | 1055         |\n",
            "|    pillow     | 26           |  plant-other  | 719          |    plastic    | 120          |\n",
            "|   platform    | 161          | playingfield  | 444          |    railing    | 405          |\n",
            "|   railroad    | 157          |     river     | 99           |     road      | 1313         |\n",
            "|     rock      | 263          |     roof      | 185          |      rug      | 242          |\n",
            "|     salad     | 30           |     sand      | 322          |      sea      | 496          |\n",
            "|     shelf     | 272          |   sky-other   | 2232         |  skyscraper   | 76           |\n",
            "|     snow      | 415          |  solid-other  | 17           |    stairs     | 180          |\n",
            "|     stone     | 130          |     straw     | 76           | structural-.. | 1027         |\n",
            "|     table     | 583          |     tent      | 59           | textile-other | 243          |\n",
            "|     towel     | 134          |     tree      | 3008         |   vegetable   | 78           |\n",
            "|  wall-brick   | 333          | wall-concrete | 211          |  wall-other   | 2451         |\n",
            "|  wall-panel   | 107          |  wall-stone   | 133          |   wall-tile   | 299          |\n",
            "|   wall-wood   | 227          |  water-other  | 392          |  waterdrops   | 18           |\n",
            "| window-blind  | 206          | window-other  | 824          |     wood      | 300          |\n",
            "|               |              |               |              |               |              |\n",
            "|     total     | 110503       |               |              |               |              |\u001b[0m\n",
            "\u001b[32m[12/13 04:07:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[12/13 04:07:51 d2.data.common]: \u001b[0mSerializing 10000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/13 04:07:52 d2.data.common]: \u001b[0mSerialized dataset takes 136.84 MiB\n",
            "\u001b[32m[12/13 04:07:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 10000 images\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/detectron2_repo/detectron2/modeling/roi_heads/fast_rcnn.py:124: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  filter_inds = filter_mask.nonzero()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/13 04:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/10000. 0.1039 s / img. ETA=0:18:29\n",
            "\u001b[32m[12/13 04:08:00 d2.evaluation.evaluator]: \u001b[0mInference done 56/10000. 0.1032 s / img. ETA=0:18:26\n",
            "\u001b[32m[12/13 04:08:05 d2.evaluation.evaluator]: \u001b[0mInference done 101/10000. 0.1042 s / img. ETA=0:18:30\n",
            "\u001b[32m[12/13 04:08:10 d2.evaluation.evaluator]: \u001b[0mInference done 146/10000. 0.1043 s / img. ETA=0:18:24\n",
            "\u001b[32m[12/13 04:08:15 d2.evaluation.evaluator]: \u001b[0mInference done 191/10000. 0.1048 s / img. ETA=0:18:19\n",
            "\u001b[32m[12/13 04:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 237/10000. 0.1049 s / img. ETA=0:18:11\n",
            "\u001b[32m[12/13 04:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 282/10000. 0.1051 s / img. ETA=0:18:07\n",
            "\u001b[32m[12/13 04:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 328/10000. 0.1048 s / img. ETA=0:18:00\n",
            "\u001b[32m[12/13 04:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 372/10000. 0.1051 s / img. ETA=0:17:59\n",
            "\u001b[32m[12/13 04:08:40 d2.evaluation.evaluator]: \u001b[0mInference done 416/10000. 0.1055 s / img. ETA=0:17:57\n",
            "\u001b[32m[12/13 04:08:45 d2.evaluation.evaluator]: \u001b[0mInference done 460/10000. 0.1058 s / img. ETA=0:17:55\n",
            "\u001b[32m[12/13 04:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 505/10000. 0.1059 s / img. ETA=0:17:49\n",
            "\u001b[32m[12/13 04:08:55 d2.evaluation.evaluator]: \u001b[0mInference done 549/10000. 0.1060 s / img. ETA=0:17:46\n",
            "\u001b[32m[12/13 04:09:00 d2.evaluation.evaluator]: \u001b[0mInference done 593/10000. 0.1061 s / img. ETA=0:17:42\n",
            "\u001b[32m[12/13 04:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 637/10000. 0.1063 s / img. ETA=0:17:38\n",
            "\u001b[32m[12/13 04:09:10 d2.evaluation.evaluator]: \u001b[0mInference done 680/10000. 0.1066 s / img. ETA=0:17:35\n",
            "\u001b[32m[12/13 04:09:16 d2.evaluation.evaluator]: \u001b[0mInference done 724/10000. 0.1068 s / img. ETA=0:17:32\n",
            "\u001b[32m[12/13 04:09:21 d2.evaluation.evaluator]: \u001b[0mInference done 767/10000. 0.1070 s / img. ETA=0:17:29\n",
            "\u001b[32m[12/13 04:09:26 d2.evaluation.evaluator]: \u001b[0mInference done 810/10000. 0.1072 s / img. ETA=0:17:26\n",
            "\u001b[32m[12/13 04:09:31 d2.evaluation.evaluator]: \u001b[0mInference done 854/10000. 0.1072 s / img. ETA=0:17:21\n",
            "\u001b[32m[12/13 04:09:36 d2.evaluation.evaluator]: \u001b[0mInference done 898/10000. 0.1073 s / img. ETA=0:17:17\n",
            "\u001b[32m[12/13 04:09:41 d2.evaluation.evaluator]: \u001b[0mInference done 940/10000. 0.1077 s / img. ETA=0:17:15\n",
            "\u001b[32m[12/13 04:09:46 d2.evaluation.evaluator]: \u001b[0mInference done 983/10000. 0.1077 s / img. ETA=0:17:11\n",
            "\u001b[32m[12/13 04:09:51 d2.evaluation.evaluator]: \u001b[0mInference done 1026/10000. 0.1079 s / img. ETA=0:17:07\n",
            "\u001b[32m[12/13 04:09:56 d2.evaluation.evaluator]: \u001b[0mInference done 1068/10000. 0.1082 s / img. ETA=0:17:05\n",
            "\u001b[32m[12/13 04:10:01 d2.evaluation.evaluator]: \u001b[0mInference done 1111/10000. 0.1082 s / img. ETA=0:17:00\n",
            "\u001b[32m[12/13 04:10:06 d2.evaluation.evaluator]: \u001b[0mInference done 1153/10000. 0.1084 s / img. ETA=0:16:57\n",
            "\u001b[32m[12/13 04:10:11 d2.evaluation.evaluator]: \u001b[0mInference done 1196/10000. 0.1085 s / img. ETA=0:16:53\n",
            "\u001b[32m[12/13 04:10:16 d2.evaluation.evaluator]: \u001b[0mInference done 1239/10000. 0.1087 s / img. ETA=0:16:49\n",
            "\u001b[32m[12/13 04:10:21 d2.evaluation.evaluator]: \u001b[0mInference done 1282/10000. 0.1088 s / img. ETA=0:16:45\n",
            "\u001b[32m[12/13 04:10:26 d2.evaluation.evaluator]: \u001b[0mInference done 1324/10000. 0.1090 s / img. ETA=0:16:42\n",
            "\u001b[32m[12/13 04:10:31 d2.evaluation.evaluator]: \u001b[0mInference done 1366/10000. 0.1092 s / img. ETA=0:16:38\n",
            "\u001b[32m[12/13 04:10:36 d2.evaluation.evaluator]: \u001b[0mInference done 1408/10000. 0.1093 s / img. ETA=0:16:34\n",
            "\u001b[32m[12/13 04:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 1450/10000. 0.1094 s / img. ETA=0:16:30\n",
            "\u001b[32m[12/13 04:10:47 d2.evaluation.evaluator]: \u001b[0mInference done 1492/10000. 0.1096 s / img. ETA=0:16:27\n",
            "\u001b[32m[12/13 04:10:52 d2.evaluation.evaluator]: \u001b[0mInference done 1534/10000. 0.1096 s / img. ETA=0:16:23\n",
            "\u001b[32m[12/13 04:10:57 d2.evaluation.evaluator]: \u001b[0mInference done 1576/10000. 0.1097 s / img. ETA=0:16:19\n",
            "\u001b[32m[12/13 04:11:02 d2.evaluation.evaluator]: \u001b[0mInference done 1618/10000. 0.1098 s / img. ETA=0:16:15\n",
            "\u001b[32m[12/13 04:11:07 d2.evaluation.evaluator]: \u001b[0mInference done 1660/10000. 0.1099 s / img. ETA=0:16:11\n",
            "\u001b[32m[12/13 04:11:12 d2.evaluation.evaluator]: \u001b[0mInference done 1700/10000. 0.1101 s / img. ETA=0:16:08\n",
            "\u001b[32m[12/13 04:11:17 d2.evaluation.evaluator]: \u001b[0mInference done 1741/10000. 0.1103 s / img. ETA=0:16:05\n",
            "\u001b[32m[12/13 04:11:22 d2.evaluation.evaluator]: \u001b[0mInference done 1783/10000. 0.1104 s / img. ETA=0:16:00\n",
            "\u001b[32m[12/13 04:11:27 d2.evaluation.evaluator]: \u001b[0mInference done 1825/10000. 0.1105 s / img. ETA=0:15:56\n",
            "\u001b[32m[12/13 04:11:32 d2.evaluation.evaluator]: \u001b[0mInference done 1867/10000. 0.1106 s / img. ETA=0:15:52\n",
            "\u001b[32m[12/13 04:11:37 d2.evaluation.evaluator]: \u001b[0mInference done 1909/10000. 0.1107 s / img. ETA=0:15:48\n",
            "\u001b[32m[12/13 04:11:42 d2.evaluation.evaluator]: \u001b[0mInference done 1951/10000. 0.1107 s / img. ETA=0:15:43\n",
            "\u001b[32m[12/13 04:11:47 d2.evaluation.evaluator]: \u001b[0mInference done 1993/10000. 0.1108 s / img. ETA=0:15:39\n",
            "\u001b[32m[12/13 04:11:52 d2.evaluation.evaluator]: \u001b[0mInference done 2034/10000. 0.1109 s / img. ETA=0:15:35\n",
            "\u001b[32m[12/13 04:11:57 d2.evaluation.evaluator]: \u001b[0mInference done 2076/10000. 0.1110 s / img. ETA=0:15:31\n",
            "\u001b[32m[12/13 04:12:02 d2.evaluation.evaluator]: \u001b[0mInference done 2118/10000. 0.1110 s / img. ETA=0:15:26\n",
            "\u001b[32m[12/13 04:12:07 d2.evaluation.evaluator]: \u001b[0mInference done 2159/10000. 0.1111 s / img. ETA=0:15:22\n",
            "\u001b[32m[12/13 04:12:12 d2.evaluation.evaluator]: \u001b[0mInference done 2200/10000. 0.1112 s / img. ETA=0:15:18\n",
            "\u001b[32m[12/13 04:12:18 d2.evaluation.evaluator]: \u001b[0mInference done 2242/10000. 0.1113 s / img. ETA=0:15:14\n",
            "\u001b[32m[12/13 04:12:23 d2.evaluation.evaluator]: \u001b[0mInference done 2284/10000. 0.1114 s / img. ETA=0:15:09\n",
            "\u001b[32m[12/13 04:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 2326/10000. 0.1114 s / img. ETA=0:15:04\n",
            "\u001b[32m[12/13 04:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 2367/10000. 0.1115 s / img. ETA=0:15:00\n",
            "\u001b[32m[12/13 04:12:38 d2.evaluation.evaluator]: \u001b[0mInference done 2409/10000. 0.1115 s / img. ETA=0:14:56\n",
            "\u001b[32m[12/13 04:12:43 d2.evaluation.evaluator]: \u001b[0mInference done 2451/10000. 0.1116 s / img. ETA=0:14:51\n",
            "\u001b[32m[12/13 04:12:48 d2.evaluation.evaluator]: \u001b[0mInference done 2493/10000. 0.1117 s / img. ETA=0:14:47\n",
            "\u001b[32m[12/13 04:12:53 d2.evaluation.evaluator]: \u001b[0mInference done 2534/10000. 0.1118 s / img. ETA=0:14:42\n",
            "\u001b[32m[12/13 04:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 2575/10000. 0.1118 s / img. ETA=0:14:38\n",
            "\u001b[32m[12/13 04:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 2616/10000. 0.1119 s / img. ETA=0:14:34\n",
            "\u001b[32m[12/13 04:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 2657/10000. 0.1120 s / img. ETA=0:14:30\n",
            "\u001b[32m[12/13 04:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 2698/10000. 0.1120 s / img. ETA=0:14:25\n",
            "\u001b[32m[12/13 04:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 2739/10000. 0.1121 s / img. ETA=0:14:21\n",
            "\u001b[32m[12/13 04:13:23 d2.evaluation.evaluator]: \u001b[0mInference done 2781/10000. 0.1121 s / img. ETA=0:14:16\n",
            "\u001b[32m[12/13 04:13:28 d2.evaluation.evaluator]: \u001b[0mInference done 2823/10000. 0.1122 s / img. ETA=0:14:11\n",
            "\u001b[32m[12/13 04:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 2864/10000. 0.1122 s / img. ETA=0:14:07\n",
            "\u001b[32m[12/13 04:13:39 d2.evaluation.evaluator]: \u001b[0mInference done 2905/10000. 0.1123 s / img. ETA=0:14:02\n",
            "\u001b[32m[12/13 04:13:44 d2.evaluation.evaluator]: \u001b[0mInference done 2946/10000. 0.1124 s / img. ETA=0:13:58\n",
            "\u001b[32m[12/13 04:13:49 d2.evaluation.evaluator]: \u001b[0mInference done 2988/10000. 0.1124 s / img. ETA=0:13:53\n",
            "\u001b[32m[12/13 04:13:54 d2.evaluation.evaluator]: \u001b[0mInference done 3029/10000. 0.1125 s / img. ETA=0:13:49\n",
            "\u001b[32m[12/13 04:13:59 d2.evaluation.evaluator]: \u001b[0mInference done 3069/10000. 0.1126 s / img. ETA=0:13:45\n",
            "\u001b[32m[12/13 04:14:04 d2.evaluation.evaluator]: \u001b[0mInference done 3110/10000. 0.1126 s / img. ETA=0:13:40\n",
            "\u001b[32m[12/13 04:14:09 d2.evaluation.evaluator]: \u001b[0mInference done 3151/10000. 0.1127 s / img. ETA=0:13:36\n",
            "\u001b[32m[12/13 04:14:14 d2.evaluation.evaluator]: \u001b[0mInference done 3192/10000. 0.1127 s / img. ETA=0:13:31\n",
            "\u001b[32m[12/13 04:14:19 d2.evaluation.evaluator]: \u001b[0mInference done 3233/10000. 0.1128 s / img. ETA=0:13:27\n",
            "\u001b[32m[12/13 04:14:24 d2.evaluation.evaluator]: \u001b[0mInference done 3275/10000. 0.1128 s / img. ETA=0:13:22\n",
            "\u001b[32m[12/13 04:14:29 d2.evaluation.evaluator]: \u001b[0mInference done 3316/10000. 0.1129 s / img. ETA=0:13:17\n",
            "\u001b[32m[12/13 04:14:34 d2.evaluation.evaluator]: \u001b[0mInference done 3357/10000. 0.1129 s / img. ETA=0:13:13\n",
            "\u001b[32m[12/13 04:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 3398/10000. 0.1130 s / img. ETA=0:13:08\n",
            "\u001b[32m[12/13 04:14:44 d2.evaluation.evaluator]: \u001b[0mInference done 3440/10000. 0.1130 s / img. ETA=0:13:03\n",
            "\u001b[32m[12/13 04:14:49 d2.evaluation.evaluator]: \u001b[0mInference done 3481/10000. 0.1131 s / img. ETA=0:12:59\n",
            "\u001b[32m[12/13 04:14:55 d2.evaluation.evaluator]: \u001b[0mInference done 3522/10000. 0.1131 s / img. ETA=0:12:54\n",
            "\u001b[32m[12/13 04:15:00 d2.evaluation.evaluator]: \u001b[0mInference done 3563/10000. 0.1132 s / img. ETA=0:12:50\n",
            "\u001b[32m[12/13 04:15:05 d2.evaluation.evaluator]: \u001b[0mInference done 3604/10000. 0.1132 s / img. ETA=0:12:45\n",
            "\u001b[32m[12/13 04:15:10 d2.evaluation.evaluator]: \u001b[0mInference done 3645/10000. 0.1133 s / img. ETA=0:12:40\n",
            "\u001b[32m[12/13 04:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 3685/10000. 0.1133 s / img. ETA=0:12:36\n",
            "\u001b[32m[12/13 04:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 3725/10000. 0.1134 s / img. ETA=0:12:32\n",
            "\u001b[32m[12/13 04:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 3767/10000. 0.1134 s / img. ETA=0:12:27\n",
            "\u001b[32m[12/13 04:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 3807/10000. 0.1135 s / img. ETA=0:12:22\n",
            "\u001b[32m[12/13 04:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 3848/10000. 0.1135 s / img. ETA=0:12:18\n",
            "\u001b[32m[12/13 04:15:40 d2.evaluation.evaluator]: \u001b[0mInference done 3889/10000. 0.1135 s / img. ETA=0:12:13\n",
            "\u001b[32m[12/13 04:15:45 d2.evaluation.evaluator]: \u001b[0mInference done 3931/10000. 0.1136 s / img. ETA=0:12:08\n",
            "\u001b[32m[12/13 04:15:50 d2.evaluation.evaluator]: \u001b[0mInference done 3971/10000. 0.1136 s / img. ETA=0:12:03\n",
            "\u001b[32m[12/13 04:15:55 d2.evaluation.evaluator]: \u001b[0mInference done 4012/10000. 0.1137 s / img. ETA=0:11:59\n",
            "\u001b[32m[12/13 04:16:00 d2.evaluation.evaluator]: \u001b[0mInference done 4052/10000. 0.1137 s / img. ETA=0:11:54\n",
            "\u001b[32m[12/13 04:16:05 d2.evaluation.evaluator]: \u001b[0mInference done 4093/10000. 0.1137 s / img. ETA=0:11:50\n",
            "\u001b[32m[12/13 04:16:10 d2.evaluation.evaluator]: \u001b[0mInference done 4135/10000. 0.1138 s / img. ETA=0:11:44\n",
            "\u001b[32m[12/13 04:16:15 d2.evaluation.evaluator]: \u001b[0mInference done 4176/10000. 0.1138 s / img. ETA=0:11:40\n",
            "\u001b[32m[12/13 04:16:21 d2.evaluation.evaluator]: \u001b[0mInference done 4217/10000. 0.1138 s / img. ETA=0:11:35\n",
            "\u001b[32m[12/13 04:16:26 d2.evaluation.evaluator]: \u001b[0mInference done 4257/10000. 0.1139 s / img. ETA=0:11:30\n",
            "\u001b[32m[12/13 04:16:31 d2.evaluation.evaluator]: \u001b[0mInference done 4298/10000. 0.1139 s / img. ETA=0:11:26\n",
            "\u001b[32m[12/13 04:16:36 d2.evaluation.evaluator]: \u001b[0mInference done 4339/10000. 0.1140 s / img. ETA=0:11:21\n",
            "\u001b[32m[12/13 04:16:41 d2.evaluation.evaluator]: \u001b[0mInference done 4381/10000. 0.1140 s / img. ETA=0:11:16\n",
            "\u001b[32m[12/13 04:16:46 d2.evaluation.evaluator]: \u001b[0mInference done 4422/10000. 0.1140 s / img. ETA=0:11:11\n",
            "\u001b[32m[12/13 04:16:51 d2.evaluation.evaluator]: \u001b[0mInference done 4463/10000. 0.1140 s / img. ETA=0:11:07\n",
            "\u001b[32m[12/13 04:16:56 d2.evaluation.evaluator]: \u001b[0mInference done 4504/10000. 0.1140 s / img. ETA=0:11:02\n",
            "\u001b[32m[12/13 04:17:01 d2.evaluation.evaluator]: \u001b[0mInference done 4545/10000. 0.1141 s / img. ETA=0:10:57\n",
            "\u001b[32m[12/13 04:17:06 d2.evaluation.evaluator]: \u001b[0mInference done 4586/10000. 0.1141 s / img. ETA=0:10:52\n",
            "\u001b[32m[12/13 04:17:11 d2.evaluation.evaluator]: \u001b[0mInference done 4626/10000. 0.1141 s / img. ETA=0:10:48\n",
            "\u001b[32m[12/13 04:17:16 d2.evaluation.evaluator]: \u001b[0mInference done 4667/10000. 0.1142 s / img. ETA=0:10:43\n",
            "\u001b[32m[12/13 04:17:21 d2.evaluation.evaluator]: \u001b[0mInference done 4707/10000. 0.1142 s / img. ETA=0:10:38\n",
            "\u001b[32m[12/13 04:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 4748/10000. 0.1142 s / img. ETA=0:10:33\n",
            "\u001b[32m[12/13 04:17:31 d2.evaluation.evaluator]: \u001b[0mInference done 4789/10000. 0.1142 s / img. ETA=0:10:29\n",
            "\u001b[32m[12/13 04:17:37 d2.evaluation.evaluator]: \u001b[0mInference done 4830/10000. 0.1143 s / img. ETA=0:10:24\n",
            "\u001b[32m[12/13 04:17:42 d2.evaluation.evaluator]: \u001b[0mInference done 4871/10000. 0.1143 s / img. ETA=0:10:19\n",
            "\u001b[32m[12/13 04:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 4913/10000. 0.1143 s / img. ETA=0:10:14\n",
            "\u001b[32m[12/13 04:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 4954/10000. 0.1143 s / img. ETA=0:10:09\n",
            "\u001b[32m[12/13 04:17:57 d2.evaluation.evaluator]: \u001b[0mInference done 4995/10000. 0.1144 s / img. ETA=0:10:04\n",
            "\u001b[32m[12/13 04:18:02 d2.evaluation.evaluator]: \u001b[0mInference done 5035/10000. 0.1144 s / img. ETA=0:10:00\n",
            "\u001b[32m[12/13 04:18:07 d2.evaluation.evaluator]: \u001b[0mInference done 5076/10000. 0.1144 s / img. ETA=0:09:55\n",
            "\u001b[32m[12/13 04:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 5117/10000. 0.1144 s / img. ETA=0:09:50\n",
            "\u001b[32m[12/13 04:18:17 d2.evaluation.evaluator]: \u001b[0mInference done 5158/10000. 0.1145 s / img. ETA=0:09:45\n",
            "\u001b[32m[12/13 04:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 5200/10000. 0.1145 s / img. ETA=0:09:40\n",
            "\u001b[32m[12/13 04:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 5241/10000. 0.1145 s / img. ETA=0:09:35\n",
            "\u001b[32m[12/13 04:18:32 d2.evaluation.evaluator]: \u001b[0mInference done 5282/10000. 0.1145 s / img. ETA=0:09:30\n",
            "\u001b[32m[12/13 04:18:37 d2.evaluation.evaluator]: \u001b[0mInference done 5322/10000. 0.1145 s / img. ETA=0:09:26\n",
            "\u001b[32m[12/13 04:18:42 d2.evaluation.evaluator]: \u001b[0mInference done 5363/10000. 0.1146 s / img. ETA=0:09:21\n",
            "\u001b[32m[12/13 04:18:47 d2.evaluation.evaluator]: \u001b[0mInference done 5403/10000. 0.1146 s / img. ETA=0:09:16\n",
            "\u001b[32m[12/13 04:18:52 d2.evaluation.evaluator]: \u001b[0mInference done 5445/10000. 0.1146 s / img. ETA=0:09:11\n",
            "\u001b[32m[12/13 04:18:57 d2.evaluation.evaluator]: \u001b[0mInference done 5485/10000. 0.1146 s / img. ETA=0:09:06\n",
            "\u001b[32m[12/13 04:19:03 d2.evaluation.evaluator]: \u001b[0mInference done 5526/10000. 0.1146 s / img. ETA=0:09:01\n",
            "\u001b[32m[12/13 04:19:08 d2.evaluation.evaluator]: \u001b[0mInference done 5566/10000. 0.1147 s / img. ETA=0:08:57\n",
            "\u001b[32m[12/13 04:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 5607/10000. 0.1147 s / img. ETA=0:08:52\n",
            "\u001b[32m[12/13 04:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 5648/10000. 0.1147 s / img. ETA=0:08:47\n",
            "\u001b[32m[12/13 04:19:23 d2.evaluation.evaluator]: \u001b[0mInference done 5689/10000. 0.1147 s / img. ETA=0:08:42\n",
            "\u001b[32m[12/13 04:19:28 d2.evaluation.evaluator]: \u001b[0mInference done 5730/10000. 0.1147 s / img. ETA=0:08:37\n",
            "\u001b[32m[12/13 04:19:33 d2.evaluation.evaluator]: \u001b[0mInference done 5771/10000. 0.1147 s / img. ETA=0:08:32\n",
            "\u001b[32m[12/13 04:19:38 d2.evaluation.evaluator]: \u001b[0mInference done 5813/10000. 0.1147 s / img. ETA=0:08:27\n",
            "\u001b[32m[12/13 04:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 5854/10000. 0.1147 s / img. ETA=0:08:22\n",
            "\u001b[32m[12/13 04:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 5895/10000. 0.1147 s / img. ETA=0:08:17\n",
            "\u001b[32m[12/13 04:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 5936/10000. 0.1148 s / img. ETA=0:08:12\n",
            "\u001b[32m[12/13 04:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 5976/10000. 0.1148 s / img. ETA=0:08:08\n",
            "\u001b[32m[12/13 04:20:03 d2.evaluation.evaluator]: \u001b[0mInference done 6017/10000. 0.1148 s / img. ETA=0:08:03\n",
            "\u001b[32m[12/13 04:20:08 d2.evaluation.evaluator]: \u001b[0mInference done 6057/10000. 0.1148 s / img. ETA=0:07:58\n",
            "\u001b[32m[12/13 04:20:13 d2.evaluation.evaluator]: \u001b[0mInference done 6098/10000. 0.1148 s / img. ETA=0:07:53\n",
            "\u001b[32m[12/13 04:20:18 d2.evaluation.evaluator]: \u001b[0mInference done 6138/10000. 0.1149 s / img. ETA=0:07:48\n",
            "\u001b[32m[12/13 04:20:23 d2.evaluation.evaluator]: \u001b[0mInference done 6180/10000. 0.1149 s / img. ETA=0:07:43\n",
            "\u001b[32m[12/13 04:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 6221/10000. 0.1149 s / img. ETA=0:07:38\n",
            "\u001b[32m[12/13 04:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 6261/10000. 0.1149 s / img. ETA=0:07:33\n",
            "\u001b[32m[12/13 04:20:39 d2.evaluation.evaluator]: \u001b[0mInference done 6302/10000. 0.1149 s / img. ETA=0:07:29\n",
            "\u001b[32m[12/13 04:20:44 d2.evaluation.evaluator]: \u001b[0mInference done 6343/10000. 0.1149 s / img. ETA=0:07:24\n",
            "\u001b[32m[12/13 04:20:49 d2.evaluation.evaluator]: \u001b[0mInference done 6384/10000. 0.1150 s / img. ETA=0:07:19\n",
            "\u001b[32m[12/13 04:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 6425/10000. 0.1150 s / img. ETA=0:07:14\n",
            "\u001b[32m[12/13 04:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 6467/10000. 0.1150 s / img. ETA=0:07:09\n",
            "\u001b[32m[12/13 04:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 6508/10000. 0.1150 s / img. ETA=0:07:04\n",
            "\u001b[32m[12/13 04:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 6549/10000. 0.1150 s / img. ETA=0:06:59\n",
            "\u001b[32m[12/13 04:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 6590/10000. 0.1150 s / img. ETA=0:06:54\n",
            "\u001b[32m[12/13 04:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 6632/10000. 0.1150 s / img. ETA=0:06:49\n",
            "\u001b[32m[12/13 04:21:24 d2.evaluation.evaluator]: \u001b[0mInference done 6673/10000. 0.1150 s / img. ETA=0:06:44\n",
            "\u001b[32m[12/13 04:21:29 d2.evaluation.evaluator]: \u001b[0mInference done 6714/10000. 0.1150 s / img. ETA=0:06:39\n",
            "\u001b[32m[12/13 04:21:34 d2.evaluation.evaluator]: \u001b[0mInference done 6755/10000. 0.1150 s / img. ETA=0:06:34\n",
            "\u001b[32m[12/13 04:21:39 d2.evaluation.evaluator]: \u001b[0mInference done 6796/10000. 0.1151 s / img. ETA=0:06:29\n",
            "\u001b[32m[12/13 04:21:44 d2.evaluation.evaluator]: \u001b[0mInference done 6836/10000. 0.1151 s / img. ETA=0:06:24\n",
            "\u001b[32m[12/13 04:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 6877/10000. 0.1151 s / img. ETA=0:06:19\n",
            "\u001b[32m[12/13 04:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 6918/10000. 0.1151 s / img. ETA=0:06:14\n",
            "\u001b[32m[12/13 04:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 6959/10000. 0.1151 s / img. ETA=0:06:09\n",
            "\u001b[32m[12/13 04:22:05 d2.evaluation.evaluator]: \u001b[0mInference done 7001/10000. 0.1151 s / img. ETA=0:06:04\n",
            "\u001b[32m[12/13 04:22:10 d2.evaluation.evaluator]: \u001b[0mInference done 7042/10000. 0.1151 s / img. ETA=0:05:59\n",
            "\u001b[32m[12/13 04:22:15 d2.evaluation.evaluator]: \u001b[0mInference done 7083/10000. 0.1151 s / img. ETA=0:05:54\n",
            "\u001b[32m[12/13 04:22:20 d2.evaluation.evaluator]: \u001b[0mInference done 7123/10000. 0.1151 s / img. ETA=0:05:49\n",
            "\u001b[32m[12/13 04:22:25 d2.evaluation.evaluator]: \u001b[0mInference done 7164/10000. 0.1152 s / img. ETA=0:05:45\n",
            "\u001b[32m[12/13 04:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 7204/10000. 0.1152 s / img. ETA=0:05:40\n",
            "\u001b[32m[12/13 04:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 7244/10000. 0.1152 s / img. ETA=0:05:35\n",
            "\u001b[32m[12/13 04:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 7285/10000. 0.1152 s / img. ETA=0:05:30\n",
            "\u001b[32m[12/13 04:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 7326/10000. 0.1152 s / img. ETA=0:05:25\n",
            "\u001b[32m[12/13 04:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 7367/10000. 0.1152 s / img. ETA=0:05:20\n",
            "\u001b[32m[12/13 04:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 7408/10000. 0.1152 s / img. ETA=0:05:15\n",
            "\u001b[32m[12/13 04:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 7448/10000. 0.1153 s / img. ETA=0:05:10\n",
            "\u001b[32m[12/13 04:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 7489/10000. 0.1153 s / img. ETA=0:05:05\n",
            "\u001b[32m[12/13 04:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 7530/10000. 0.1153 s / img. ETA=0:05:00\n",
            "\u001b[32m[12/13 04:23:16 d2.evaluation.evaluator]: \u001b[0mInference done 7571/10000. 0.1153 s / img. ETA=0:04:55\n",
            "\u001b[32m[12/13 04:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 7613/10000. 0.1153 s / img. ETA=0:04:50\n",
            "\u001b[32m[12/13 04:23:26 d2.evaluation.evaluator]: \u001b[0mInference done 7654/10000. 0.1153 s / img. ETA=0:04:45\n",
            "\u001b[32m[12/13 04:23:31 d2.evaluation.evaluator]: \u001b[0mInference done 7695/10000. 0.1153 s / img. ETA=0:04:40\n",
            "\u001b[32m[12/13 04:23:36 d2.evaluation.evaluator]: \u001b[0mInference done 7736/10000. 0.1153 s / img. ETA=0:04:35\n",
            "\u001b[32m[12/13 04:23:41 d2.evaluation.evaluator]: \u001b[0mInference done 7777/10000. 0.1153 s / img. ETA=0:04:30\n",
            "\u001b[32m[12/13 04:23:46 d2.evaluation.evaluator]: \u001b[0mInference done 7817/10000. 0.1153 s / img. ETA=0:04:25\n",
            "\u001b[32m[12/13 04:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 7858/10000. 0.1153 s / img. ETA=0:04:21\n",
            "\u001b[32m[12/13 04:23:56 d2.evaluation.evaluator]: \u001b[0mInference done 7899/10000. 0.1154 s / img. ETA=0:04:16\n",
            "\u001b[32m[12/13 04:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 7940/10000. 0.1154 s / img. ETA=0:04:11\n",
            "\u001b[32m[12/13 04:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 7981/10000. 0.1154 s / img. ETA=0:04:06\n",
            "\u001b[32m[12/13 04:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 8021/10000. 0.1154 s / img. ETA=0:04:01\n",
            "\u001b[32m[12/13 04:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 8062/10000. 0.1154 s / img. ETA=0:03:56\n",
            "\u001b[32m[12/13 04:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 8104/10000. 0.1154 s / img. ETA=0:03:51\n",
            "\u001b[32m[12/13 04:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 8146/10000. 0.1154 s / img. ETA=0:03:45\n",
            "\u001b[32m[12/13 04:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 8187/10000. 0.1154 s / img. ETA=0:03:40\n",
            "\u001b[32m[12/13 04:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 8227/10000. 0.1154 s / img. ETA=0:03:36\n",
            "\u001b[32m[12/13 04:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 8268/10000. 0.1154 s / img. ETA=0:03:31\n",
            "\u001b[32m[12/13 04:24:47 d2.evaluation.evaluator]: \u001b[0mInference done 8309/10000. 0.1154 s / img. ETA=0:03:26\n",
            "\u001b[32m[12/13 04:24:52 d2.evaluation.evaluator]: \u001b[0mInference done 8349/10000. 0.1154 s / img. ETA=0:03:21\n",
            "\u001b[32m[12/13 04:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 8391/10000. 0.1154 s / img. ETA=0:03:16\n",
            "\u001b[32m[12/13 04:25:02 d2.evaluation.evaluator]: \u001b[0mInference done 8431/10000. 0.1155 s / img. ETA=0:03:11\n",
            "\u001b[32m[12/13 04:25:07 d2.evaluation.evaluator]: \u001b[0mInference done 8473/10000. 0.1154 s / img. ETA=0:03:06\n",
            "\u001b[32m[12/13 04:25:12 d2.evaluation.evaluator]: \u001b[0mInference done 8514/10000. 0.1155 s / img. ETA=0:03:01\n",
            "\u001b[32m[12/13 04:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 8554/10000. 0.1155 s / img. ETA=0:02:56\n",
            "\u001b[32m[12/13 04:25:22 d2.evaluation.evaluator]: \u001b[0mInference done 8595/10000. 0.1155 s / img. ETA=0:02:51\n",
            "\u001b[32m[12/13 04:25:27 d2.evaluation.evaluator]: \u001b[0mInference done 8635/10000. 0.1155 s / img. ETA=0:02:46\n",
            "\u001b[32m[12/13 04:25:32 d2.evaluation.evaluator]: \u001b[0mInference done 8675/10000. 0.1155 s / img. ETA=0:02:41\n",
            "\u001b[32m[12/13 04:25:37 d2.evaluation.evaluator]: \u001b[0mInference done 8715/10000. 0.1155 s / img. ETA=0:02:36\n",
            "\u001b[32m[12/13 04:25:42 d2.evaluation.evaluator]: \u001b[0mInference done 8756/10000. 0.1155 s / img. ETA=0:02:31\n",
            "\u001b[32m[12/13 04:25:47 d2.evaluation.evaluator]: \u001b[0mInference done 8798/10000. 0.1155 s / img. ETA=0:02:26\n",
            "\u001b[32m[12/13 04:25:52 d2.evaluation.evaluator]: \u001b[0mInference done 8838/10000. 0.1155 s / img. ETA=0:02:21\n",
            "\u001b[32m[12/13 04:25:57 d2.evaluation.evaluator]: \u001b[0mInference done 8879/10000. 0.1155 s / img. ETA=0:02:16\n",
            "\u001b[32m[12/13 04:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 8920/10000. 0.1155 s / img. ETA=0:02:11\n",
            "\u001b[32m[12/13 04:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 8961/10000. 0.1155 s / img. ETA=0:02:06\n",
            "\u001b[32m[12/13 04:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 9002/10000. 0.1156 s / img. ETA=0:02:01\n",
            "\u001b[32m[12/13 04:26:17 d2.evaluation.evaluator]: \u001b[0mInference done 9043/10000. 0.1156 s / img. ETA=0:01:56\n",
            "\u001b[32m[12/13 04:26:22 d2.evaluation.evaluator]: \u001b[0mInference done 9084/10000. 0.1156 s / img. ETA=0:01:51\n",
            "\u001b[32m[12/13 04:26:27 d2.evaluation.evaluator]: \u001b[0mInference done 9126/10000. 0.1156 s / img. ETA=0:01:46\n",
            "\u001b[32m[12/13 04:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 9168/10000. 0.1156 s / img. ETA=0:01:41\n",
            "\u001b[32m[12/13 04:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 9208/10000. 0.1156 s / img. ETA=0:01:36\n",
            "\u001b[32m[12/13 04:26:43 d2.evaluation.evaluator]: \u001b[0mInference done 9249/10000. 0.1156 s / img. ETA=0:01:31\n",
            "\u001b[32m[12/13 04:26:48 d2.evaluation.evaluator]: \u001b[0mInference done 9290/10000. 0.1156 s / img. ETA=0:01:26\n",
            "\u001b[32m[12/13 04:26:53 d2.evaluation.evaluator]: \u001b[0mInference done 9330/10000. 0.1156 s / img. ETA=0:01:21\n",
            "\u001b[32m[12/13 04:26:58 d2.evaluation.evaluator]: \u001b[0mInference done 9370/10000. 0.1156 s / img. ETA=0:01:16\n",
            "\u001b[32m[12/13 04:27:03 d2.evaluation.evaluator]: \u001b[0mInference done 9411/10000. 0.1156 s / img. ETA=0:01:11\n",
            "\u001b[32m[12/13 04:27:08 d2.evaluation.evaluator]: \u001b[0mInference done 9452/10000. 0.1156 s / img. ETA=0:01:06\n",
            "\u001b[32m[12/13 04:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 9492/10000. 0.1157 s / img. ETA=0:01:02\n",
            "\u001b[32m[12/13 04:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 9534/10000. 0.1157 s / img. ETA=0:00:56\n",
            "\u001b[32m[12/13 04:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 9574/10000. 0.1157 s / img. ETA=0:00:52\n",
            "\u001b[32m[12/13 04:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 9615/10000. 0.1157 s / img. ETA=0:00:47\n",
            "\u001b[32m[12/13 04:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 9656/10000. 0.1157 s / img. ETA=0:00:42\n",
            "\u001b[32m[12/13 04:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 9698/10000. 0.1157 s / img. ETA=0:00:36\n",
            "\u001b[32m[12/13 04:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 9739/10000. 0.1157 s / img. ETA=0:00:31\n",
            "\u001b[32m[12/13 04:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 9779/10000. 0.1157 s / img. ETA=0:00:27\n",
            "\u001b[32m[12/13 04:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 9820/10000. 0.1157 s / img. ETA=0:00:22\n",
            "\u001b[32m[12/13 04:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 9861/10000. 0.1157 s / img. ETA=0:00:16\n",
            "\u001b[32m[12/13 04:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 9901/10000. 0.1157 s / img. ETA=0:00:12\n",
            "\u001b[32m[12/13 04:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 9943/10000. 0.1157 s / img. ETA=0:00:06\n",
            "\u001b[32m[12/13 04:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 9984/10000. 0.1157 s / img. ETA=0:00:01\n",
            "\u001b[32m[12/13 04:28:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:20:22.531297 (0.122314 s / img per device, on 1 devices)\n",
            "\u001b[32m[12/13 04:28:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:19:16 (0.115740 s / img per device, on 1 devices)\n",
            "\u001b[32m[12/13 04:28:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[12/13 04:28:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
            "\u001b[32m[12/13 04:28:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished in 35.57 seconds.\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished in 1.65 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.213\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.127\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.055\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.125\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.157\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.112\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.154\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.154\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.202\n",
            "\u001b[32m[12/13 04:28:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
            "| 12.158 | 21.302 | 12.706 | 5.531 | 12.453 | 15.653 |\n",
            "\u001b[32m[12/13 04:28:55 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category        | AP     | category      | AP     | category         | AP     |\n",
            "|:----------------|:-------|:--------------|:-------|:-----------------|:-------|\n",
            "| person          | 42.630 | bicycle       | 21.149 | car              | 25.863 |\n",
            "| motorcycle      | 25.567 | airplane      | 15.451 | bus              | 29.700 |\n",
            "| train           | 30.359 | truck         | 10.641 | boat             | 13.037 |\n",
            "| traffic light   | 23.141 | fire hydrant  | 46.915 | stop sign        | 48.988 |\n",
            "| parking meter   | 22.856 | bench         | 14.092 | bird             | 19.432 |\n",
            "| cat             | 43.664 | dog           | 22.649 | horse            | 34.193 |\n",
            "| sheep           | 20.689 | cow           | 30.690 | elephant         | 49.088 |\n",
            "| bear            | 43.675 | zebra         | 50.229 | giraffe          | 50.951 |\n",
            "| backpack        | 9.523  | umbrella      | 10.679 | handbag          | 7.978  |\n",
            "| tie             | 23.886 | suitcase      | 10.855 | frisbee          | 44.738 |\n",
            "| skis            | 10.798 | snowboard     | 12.931 | sports ball      | 30.536 |\n",
            "| kite            | 18.060 | baseball bat  | 18.166 | baseball glove   | 25.957 |\n",
            "| skateboard      | 24.821 | surfboard     | 25.305 | tennis racket    | 35.806 |\n",
            "| bottle          | 24.237 | wine glass    | 19.115 | cup              | 30.000 |\n",
            "| fork            | 16.016 | knife         | 9.703  | spoon            | 5.973  |\n",
            "| bowl            | 10.435 | banana        | 13.798 | apple            | 11.691 |\n",
            "| sandwich        | 12.433 | orange        | 12.563 | broccoli         | 14.855 |\n",
            "| carrot          | 19.408 | hot dog       | 14.721 | pizza            | 45.129 |\n",
            "| donut           | 21.741 | cake          | 21.373 | chair            | 14.603 |\n",
            "| couch           | 26.648 | potted plant  | 14.452 | bed              | 28.951 |\n",
            "| dining table    | 12.380 | toilet        | 45.392 | tv               | 30.197 |\n",
            "| laptop          | 35.576 | mouse         | 29.787 | remote           | 19.331 |\n",
            "| keyboard        | 29.927 | cell phone    | 15.927 | microwave        | 28.220 |\n",
            "| oven            | 9.760  | toaster       | 0.000  | sink             | 21.344 |\n",
            "| refrigerator    | 12.944 | book          | 3.277  | clock            | 39.098 |\n",
            "| vase            | 31.027 | scissors      | 10.577 | teddy bear       | 24.604 |\n",
            "| hair drier      | 0.000  | toothbrush    | 10.751 | banner           | 0.000  |\n",
            "| blanket         | 0.000  | branch        | 0.000  | bridge           | 0.000  |\n",
            "| building-other  | 2.582  | bush          | 0.000  | cabinet          | 1.040  |\n",
            "| cage            | 0.000  | cardboard     | 0.000  | carpet           | 0.000  |\n",
            "| ceiling-other   | 9.792  | ceiling-tile  | 0.000  | cloth            | 0.000  |\n",
            "| clothes         | 0.000  | clouds        | 7.806  | counter          | 0.710  |\n",
            "| cupboard        | 0.000  | curtain       | 1.976  | desk-stuff       | 3.085  |\n",
            "| dirt            | 1.828  | door-stuff    | 0.891  | fence            | 0.693  |\n",
            "| floor-marble    | 0.000  | floor-other   | 0.000  | floor-stone      | 0.000  |\n",
            "| floor-tile      | 5.864  | floor-wood    | 1.008  | flower           | 0.929  |\n",
            "| fog             | 0.000  | food-other    | 0.000  | fruit            | 0.000  |\n",
            "| furniture-other | 0.000  | grass         | 21.504 | gravel           | 0.000  |\n",
            "| ground-other    | 0.000  | hill          | 0.000  | house            | 0.594  |\n",
            "| leaves          | 0.000  | light         | 0.174  | mat              | 0.000  |\n",
            "| metal           | 0.000  | mirror-stuff  | 0.226  | moss             | 0.000  |\n",
            "| mountain        | 0.000  | mud           | 0.000  | napkin           | 0.000  |\n",
            "| net             | 0.000  | paper         | 0.000  | pavement         | 2.213  |\n",
            "| pillow          | 0.000  | plant-other   | 0.693  | plastic          | 0.000  |\n",
            "| platform        | 0.000  | playingfield  | 35.199 | railing          | 0.000  |\n",
            "| railroad        | 1.584  | river         | 0.000  | road             | 21.694 |\n",
            "| rock            | 0.000  | roof          | 0.000  | rug              | 0.000  |\n",
            "| salad           | 0.000  | sand          | 1.644  | sea              | 21.923 |\n",
            "| shelf           | 0.000  | sky-other     | 21.741 | skyscraper       | 0.000  |\n",
            "| snow            | 37.502 | solid-other   | 0.000  | stairs           | 0.000  |\n",
            "| stone           | 0.000  | straw         | 0.000  | structural-other | 0.000  |\n",
            "| table           | 0.000  | tent          | 0.000  | textile-other    | 0.000  |\n",
            "| towel           | 0.000  | tree          | 16.027 | vegetable        | 0.000  |\n",
            "| wall-brick      | 0.000  | wall-concrete | 0.000  | wall-other       | 8.832  |\n",
            "| wall-panel      | 0.000  | wall-stone    | 0.000  | wall-tile        | 4.324  |\n",
            "| wall-wood       | 0.000  | water-other   | 0.297  | waterdrops       | 0.000  |\n",
            "| window-blind    | 0.000  | window-other  | 1.031  | wood             | 0.000  |\n",
            "Loading and preparing results...\n",
            "DONE (t=1.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *segm*\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6b72f43f00a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCURRENT_CATALOG_NAME\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# another equivalent way to evaluate the model is to use `trainer.test`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2_repo/detectron2/evaluation/evaluator.py\u001b[0m in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator)\u001b[0m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0;31m# An evaluator may return None when not in main process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# Replace it by an empty dict instead to make it easier for downstream code to handle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2_repo/detectron2/evaluation/coco_evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, img_ids)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_box_proposals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"instances\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;31m# Copy so the caller can do whatever with results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2_repo/detectron2/evaluation/coco_evaluation.py\u001b[0m in \u001b[0;36m_eval_predictions\u001b[0;34m(self, predictions, img_ids)\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0mimg_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 )\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoco_results\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# cocoapi does not handle empty results very well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             )\n",
            "\u001b[0;32m/content/detectron2_repo/detectron2/evaluation/coco_evaluation.py\u001b[0m in \u001b[0;36m_evaluate_predictions_on_coco\u001b[0;34m(coco_gt, coco_results, iou_type, kpt_oks_sigmas, use_fast_impl, img_ids)\u001b[0m\n\u001b[1;32m    570\u001b[0m         )\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0mcoco_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \u001b[0mcoco_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0mcoco_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2_repo/detectron2/evaluation/fast_eval_api.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# loop through images, area range, max detection number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2_repo/detectron2/evaluation/fast_eval_api.py\u001b[0m in \u001b[0;36mnew_prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# convert ground truth to mask if iouType == 'segm'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miouType\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'segm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0m_toMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcocoGt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0m_toMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcocoDt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# set ignore flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/detectron2_repo/detectron2/evaluation/fast_eval_api.py\u001b[0m in \u001b[0;36m_toMask\u001b[0;34m(anns, coco)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mann\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segmentation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segmentation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segmentation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mrle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannToRLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mann\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'segmentation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: data type not understood"
          ]
        }
      ]
    }
  ]
}